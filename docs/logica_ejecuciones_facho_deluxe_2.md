# ğŸ”„ LÃ³gica de Ejecuciones - Facho Deluxe v2

## ğŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Workflows y su Funcionamiento](#workflows-y-su-funcionamiento)
4. [RelaciÃ³n con OIDs](#relaciÃ³n-con-oids)
5. [Sistema de EjecuciÃ³n](#sistema-de-ejecuciÃ³n)
6. [Coordinador de Ejecuciones](#coordinador-de-ejecuciones)
7. [Prioridades y Orden de EjecuciÃ³n](#prioridades-y-orden-de-ejecuciÃ³n)
8. [PrevenciÃ³n de SaturaciÃ³n](#prevenciÃ³n-de-saturaciÃ³n)
9. [Flujos Detallados](#flujos-detallados)
10. [IntegraciÃ³n con Celery](#integraciÃ³n-con-celery)

---

## ğŸ¯ IntroducciÃ³n

Facho Deluxe v2 implementa un sistema complejo de gestiÃ³n de workflows SNMP que permite ejecutar tareas de descubrimiento y monitoreo sobre mÃºltiples OLTs de manera coordinada, eficiente y sin saturar el sistema.

### Conceptos Clave

- **Workflow**: Conjunto de nodos (tareas) que se ejecutan sobre una OLT especÃ­fica
- **Nodo**: Tarea individual dentro de un workflow (ej: descubrimiento de ONUs, GET de estado)
- **OID**: Identificador SNMP que define quÃ© operaciÃ³n realizar (descubrimiento o GET)
- **Coordinador**: Sistema inteligente que gestiona la ejecuciÃ³n de tareas
- **Celery**: Sistema de colas de tareas asÃ­ncronas

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DJANGO BACKEND                                â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  WorkflowTemplate â”‚â”€â”€â”€â–¶â”‚  WorkflowTemplateâ”‚                 â”‚
â”‚  â”‚   (Plantilla)     â”‚    â”‚      Node        â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚           â”‚                        â”‚                            â”‚
â”‚           â”‚                        â–¼                            â”‚
â”‚           â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚           â”‚              â”‚      OID          â”‚                  â”‚
â”‚           â”‚              â”‚  (descubrimiento/ â”‚                  â”‚
â”‚           â”‚              â”‚      get)         â”‚                  â”‚
â”‚           â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚           â”‚                        â”‚                            â”‚
â”‚           â–¼                        â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚                            â”‚
â”‚  â”‚  OLTWorkflow     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚  â”‚  (Instancia)     â”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  WorkflowNode    â”‚                                            â”‚
â”‚  â”‚  (Tarea real)    â”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  SnmpJob         â”‚                                            â”‚
â”‚  â”‚  SnmpJobHost     â”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXECUTION COORDINATOR                               â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Coordinator Loop (Celery Beat - cada 5 segundos)        â”‚   â”‚
â”‚  â”‚  â€¢ Lee estado de todas las OLTs activas                  â”‚   â”‚
â”‚  â”‚  â€¢ Detecta cambios (hash comparison)                     â”‚   â”‚
â”‚  â”‚  â€¢ Procesa tareas listas                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                  â”‚                                               â”‚
â”‚                  â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Dynamic Scheduler                                        â”‚   â”‚
â”‚  â”‚  â€¢ Identifica tareas con next_run_at <= now              â”‚   â”‚
â”‚  â”‚  â€¢ Verifica si OLT estÃ¡ ocupada                          â”‚   â”‚
â”‚  â”‚  â€¢ Ordena por prioridad                                  â”‚   â”‚
â”‚  â”‚  â€¢ Ejecuta o encola                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                  â”‚                                               â”‚
â”‚                  â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Redis Queue (olt:queue:{olt_id})                        â”‚   â”‚
â”‚  â”‚  â€¢ Almacena tareas pendientes por OLT                    â”‚   â”‚
â”‚  â”‚  â€¢ Ordenadas por prioridad                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CELERY WORKERS                                â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Discovery    â”‚  â”‚ GET Main     â”‚  â”‚ Coordinator  â”‚          â”‚
â”‚  â”‚ Queue        â”‚  â”‚ Queue        â”‚  â”‚ Queue        â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                 â”‚                  â”‚                   â”‚
â”‚         â–¼                 â–¼                  â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Workers ejecutan tareas SNMP                            â”‚   â”‚
â”‚  â”‚  â€¢ discovery_main_task                                   â”‚   â”‚
â”‚  â”‚  â€¢ get_main_task                                         â”‚   â”‚
â”‚  â”‚  â€¢ coordinator_loop_task                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                  â”‚                                               â”‚
â”‚                  â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Callbacks                                                â”‚   â”‚
â”‚  â”‚  â€¢ on_task_completed() â†’ ejecuta siguiente en cola      â”‚   â”‚
â”‚  â”‚  â€¢ on_task_failed() â†’ maneja errores                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Workflows y su Funcionamiento

### Â¿QuÃ© es un Workflow?

Un **Workflow** es una colecciÃ³n de nodos (tareas) que se ejecutan sobre una OLT especÃ­fica. Es similar a las plantillas de Zabbix: defines una plantilla con mÃºltiples items y luego la aplicas a mÃºltiples hosts (OLTs).

### Componentes de un Workflow

#### 1. **WorkflowTemplate** (Plantilla)
- Define la estructura reutilizable de un workflow
- Contiene mÃºltiples `WorkflowTemplateNode`
- Se puede aplicar a mÃºltiples OLTs
- Ejemplo: "MA5800 Discovery BÃ¡sico"

#### 2. **WorkflowTemplateNode** (Nodo de Plantilla)
- Define una tarea dentro de la plantilla
- **Depende directamente de un OID** (no de TaskTemplate)
- Contiene:
  - `key`: Identificador Ãºnico del nodo (ej: "discovery.onus")
  - `oid`: OID SNMP que define marca, modelo y tipo de operaciÃ³n
  - `interval_seconds`: Intervalo de ejecuciÃ³n
  - `priority`: Prioridad de ejecuciÃ³n (1-100)
  - `enabled`: Si estÃ¡ habilitado o no
  - `parameters`: ParÃ¡metros adicionales en JSON

#### 3. **OLTWorkflow** (Instancia de Workflow)
- Instancia especÃ­fica de un workflow para una OLT
- Se crea automÃ¡ticamente al aplicar una plantilla
- Contiene mÃºltiples `WorkflowNode`

#### 4. **WorkflowNode** (Nodo Real)
- Tarea real que se ejecuta en una OLT especÃ­fica
- Puede estar vinculado a un `WorkflowTemplateNode` (si viene de plantilla)
- O ser un nodo custom (creado manualmente)
- Se convierte en `SnmpJob` y `SnmpJobHost` para ejecuciÃ³n

### Flujo de CreaciÃ³n de Workflow

```
1. Usuario crea WorkflowTemplate
   â””â”€ Nombre: "MA5800 Discovery BÃ¡sico"
   
2. Usuario agrega WorkflowTemplateNode a la plantilla
   â””â”€ key: "discovery.onus"
   â””â”€ oid: OID de descubrimiento (ej: 1.3.6.1.4.1.2011.6.128.1.1.2.46.1.1)
   â””â”€ interval_seconds: 180
   â””â”€ priority: 1 (descubrimiento tiene prioridad 1)
   
3. Usuario aplica plantilla a OLTs
   â””â”€ Selecciona OLTs: SMP-10, SMP-11, SMP-12
   â””â”€ Sistema crea OLTWorkflow para cada OLT
   â””â”€ Sistema crea WorkflowNode para cada WorkflowTemplateNode
   
4. Sistema convierte WorkflowNode en SnmpJob + SnmpJobHost
   â””â”€ WorkflowNode â†’ SnmpJob (plantilla de tarea)
   â””â”€ WorkflowNode â†’ SnmpJobHost (instancia por OLT)
   â””â”€ SnmpJobHost.next_run_at se calcula automÃ¡ticamente
```

---

## ğŸ”— RelaciÃ³n con OIDs

### Dependencia Directa de OIDs

**IMPORTANTE**: Los nodos de workflow **dependen directamente de OIDs**, no de TaskTemplates.

#### Â¿QuÃ© es un OID?

Un **OID** (Object Identifier) define:
- **Marca**: Fabricante (Huawei, ZTE, etc.)
- **Modelo**: Modelo especÃ­fico (MA5800, C320, etc.)
- **Espacio**: Tipo de operaciÃ³n
  - `descubrimiento`: Para descubrir elementos (ONUs, puertos, etc.)
  - `get`: Para obtener valores especÃ­ficos (estado, mÃ©tricas, etc.)
- **OID SNMP**: El identificador real (ej: `1.3.6.1.4.1.2011.6.128.1.1.2.46.1.1`)

#### Flujo de SelecciÃ³n de TaskTemplate

Cuando se crea un `WorkflowNode` desde un `WorkflowTemplateNode`:

```
1. WorkflowTemplateNode tiene un OID asignado
   â””â”€ oid.espacio = "descubrimiento" o "get"
   
2. Sistema busca TaskTemplate apropiado:
   â””â”€ Si espacio == "descubrimiento":
      â†’ Busca TaskFunction con function_type = "descubrimiento"
      â†’ Busca TaskTemplate con esa funciÃ³n
   â””â”€ Si espacio == "get":
      â†’ Busca TaskFunction con function_type = "get"
      â†’ Busca TaskTemplate con esa funciÃ³n
   
3. TaskTemplate encontrado se asigna al WorkflowNode
   â””â”€ WorkflowNode.template = TaskTemplate
   â””â”€ Este TaskTemplate define quÃ© funciÃ³n Python ejecutar
```

### Ejemplo PrÃ¡ctico

```
OID: 1.3.6.1.4.1.2011.6.128.1.1.2.46.1.1
â”œâ”€ Marca: Huawei
â”œâ”€ Modelo: MA5800
â”œâ”€ Espacio: descubrimiento
â””â”€ Nombre: "Discovery ONUs"

WorkflowTemplateNode:
â”œâ”€ key: "discovery.onus"
â”œâ”€ oid: [OID anterior]
â”œâ”€ interval_seconds: 180
â””â”€ priority: 1

Al crear WorkflowNode:
â”œâ”€ Busca TaskTemplate con funciÃ³n "descubrimiento"
â”œâ”€ Encuentra: "Discovery Huawei MA5800"
â””â”€ Asigna: WorkflowNode.template = TaskTemplate
```

---

## âš™ï¸ Sistema de EjecuciÃ³n

### EjecuciÃ³n Individual vs Grupal

#### EjecuciÃ³n Individual

Cada **WorkflowNode** se ejecuta **independientemente**:

- Cada nodo tiene su propio `interval_seconds`
- Cada nodo tiene su propio `priority`
- Cada nodo se convierte en un `SnmpJob` separado
- Cada `SnmpJob` tiene mÃºltiples `SnmpJobHost` (uno por OLT)

**Ejemplo**:
```
Workflow "SMP-10" tiene 3 nodos:
â”œâ”€ Nodo 1: Discovery ONUs (interval: 180s, priority: 1)
â”œâ”€ Nodo 2: GET Estado ONUs (interval: 60s, priority: 3)
â””â”€ Nodo 3: GET MÃ©tricas (interval: 300s, priority: 3)

Cada uno se ejecuta independientemente segÃºn su intervalo.
```

#### EjecuciÃ³n por OLT

Aunque los nodos son independientes, **el coordinador los ejecuta de forma coordinada**:

- Solo **una tarea SNMP pesada por OLT a la vez**
- Si una OLT estÃ¡ ocupada, las demÃ¡s tareas se encolan
- El coordinador gestiona las colas por OLT

### ConversiÃ³n de WorkflowNode a SnmpJob

```
WorkflowNode (definiciÃ³n)
    â”‚
    â”œâ”€ Se convierte en SnmpJob (plantilla)
    â”‚  â””â”€ SnmpJob.nombre = WorkflowNode.name
    â”‚  â””â”€ SnmpJob.oid = WorkflowNode.template_node.oid
    â”‚  â””â”€ SnmpJob.interval_seconds = WorkflowNode.interval_seconds
    â”‚  â””â”€ SnmpJob.job_type = OID.espacio (descubrimiento/get)
    â”‚
    â””â”€ Se crea SnmpJobHost por cada OLT
       â””â”€ SnmpJobHost.olt = OLT especÃ­fica
       â””â”€ SnmpJobHost.next_run_at = calculado automÃ¡ticamente
       â””â”€ SnmpJobHost.enabled = WorkflowNode.enabled
```

---

## ğŸ® Coordinador de Ejecuciones

### Â¿QuÃ© es el Coordinador?

El **Execution Coordinator** es el "cerebro" del sistema que:

1. **Monitorea** continuamente el estado de todas las OLTs
2. **Planifica** dinÃ¡micamente cuÃ¡ndo ejecutar cada tarea
3. **Prioriza** tareas segÃºn importancia
4. **Previene** colisiones entre tareas
5. **Optimiza** el uso de recursos

### Componentes del Coordinador

#### 1. **Coordinator Loop** (`coordinator_loop_task`)

- **Ejecuta cada 5 segundos** (Celery Beat)
- **Lee el estado** de todas las OLTs activas
- **Detecta cambios** comparando hashes de estado
- **Procesa tareas listas** mediante Dynamic Scheduler

```python
@shared_task(queue='coordinator', bind=True)
def coordinator_loop_task(self):
    """
    Loop principal que se ejecuta cada 5 segundos
    """
    active_olts = OLT.objects.filter(habilitar_olt=True)
    
    for olt in active_olts:
        # 1. Auto-corregir desfases
        _auto_fix_offset(olt.id)
        
        # 2. Leer estado actual
        coordinator = ExecutionCoordinator(olt.id)
        current_state = coordinator.get_system_state()
        
        # 3. Procesar tareas listas
        scheduler = DynamicScheduler(olt.id)
        tasks_processed = scheduler.process_ready_tasks(olt)
```

#### 2. **Dynamic Scheduler** (`dynamic_scheduler.py`)

- **Identifica tareas listas**: `SnmpJobHost.next_run_at <= now`
- **Verifica si OLT estÃ¡ ocupada**: `is_olt_busy()`
- **Ordena por prioridad**: Discovery (90) > GET (40)
- **Ejecuta o encola**: SegÃºn disponibilidad

#### 3. **Execution Coordinator** (`coordinator.py`)

- **Lee estado completo** del sistema
- **Calcula hashes** para detecciÃ³n rÃ¡pida de cambios
- **Gestiona estado anterior** para comparaciÃ³n

### Flujo del Coordinador

```
Cada 5 segundos:
â”‚
â”œâ”€ 1. Para cada OLT activa:
â”‚  â”‚
â”‚  â”œâ”€ 2. Auto-corregir desfases de tiempo
â”‚  â”‚  â””â”€ Discovery â†’ :00 segundos
â”‚  â”‚  â””â”€ GET â†’ :10 segundos
â”‚  â”‚
â”‚  â”œâ”€ 3. Leer estado actual
â”‚  â”‚  â””â”€ SnmpJobHost habilitados
â”‚  â”‚  â””â”€ Executions en curso
â”‚  â”‚  â””â”€ Cola Redis
â”‚  â”‚
â”‚  â”œâ”€ 4. Detectar cambios (hash comparison)
â”‚  â”‚  â””â”€ Si hay cambios â†’ reformular plan
â”‚  â”‚
â”‚  â””â”€ 5. Procesar tareas listas
â”‚     â””â”€ Dynamic Scheduler
â”‚        â”œâ”€ Obtener tareas con next_run_at <= now
â”‚        â”œâ”€ Ordenar por prioridad
â”‚        â”œâ”€ Verificar si OLT estÃ¡ ocupada
â”‚        â””â”€ Ejecutar o encolar
```

---

## ğŸ¯ Prioridades y Orden de EjecuciÃ³n

### Sistema de Prioridades

Las tareas tienen **prioridades numÃ©ricas** (1-100):

| Prioridad | Tipo de Tarea | DescripciÃ³n |
|-----------|---------------|-------------|
| **90** | Discovery | Descubrimiento de elementos (ONUs, puertos) |
| **40** | GET | ObtenciÃ³n de valores especÃ­ficos |
| **30** | WALK | Recorrido de Ã¡rbol SNMP |
| **50** | Otros | Tareas miscelÃ¡neas |

### CÃ¡lculo de Prioridad

La prioridad se calcula automÃ¡ticamente segÃºn el tipo de job:

```python
def calculate_priority(job_type):
    if job_type == 'descubrimiento':
        return 90  # MÃ¡xima prioridad
    elif job_type == 'get':
        return 40  # Prioridad media
    elif job_type == 'walk':
        return 30  # Prioridad baja
    else:
        return 50  # Default
```

### Orden de EjecuciÃ³n

1. **Discovery siempre primero**: Si hay tareas de descubrimiento listas, se ejecutan antes que GET
2. **GET espera**: Si hay discovery en curso o pendiente, GET se encola
3. **Orden dentro del mismo tipo**: Por nombre (alfabÃ©tico)

**Ejemplo**:
```
Tareas listas para OLT SMP-10:
â”œâ”€ Discovery ONUs (P90) â†’ Ejecuta PRIMERO
â”œâ”€ GET Estado ONU-1 (P40) â†’ Encolada (hay discovery)
â”œâ”€ GET Estado ONU-2 (P40) â†’ Encolada
â””â”€ Discovery Puertos (P90) â†’ Ejecuta DESPUÃ‰S del primero

Orden de ejecuciÃ³n:
1. Discovery ONUs
2. Discovery Puertos
3. GET Estado ONU-1
4. GET Estado ONU-2
```

---

## ğŸ›¡ï¸ PrevenciÃ³n de SaturaciÃ³n

### Mecanismos de ProtecciÃ³n

#### 1. **LÃ­mite de Capacidad por Tipo**

El sistema verifica la capacidad de Celery antes de ejecutar:

```python
CAPACITY_LIMITS = {
    'descubrimiento': 25,  # MÃ¡ximo 25 Discovery PENDING
    'get': 25             # MÃ¡ximo 25 GET PENDING
}

def _check_celery_capacity(job_type):
    pending_count = Execution.objects.filter(
        status='PENDING',
        snmp_job__job_type=job_type
    ).count()
    
    if pending_count >= CAPACITY_LIMITS[job_type]:
        return False  # Sistema saturado
    return True
```

#### 2. **Una Tarea por OLT**

- Solo **una tarea SNMP pesada por OLT a la vez**
- Si OLT estÃ¡ ocupada, otras tareas se encolan en Redis
- Cola por OLT: `olt:queue:{olt_id}`

#### 3. **Locks Anti-Duplicados**

- Lock atÃ³mico de 5 segundos antes de ejecutar
- Previene ejecuciones duplicadas
- Verifica `last_run_at` (no ejecutar si < 3 segundos)

#### 4. **Desfases de Tiempo**

- **Discovery**: Se ejecuta en `:00` segundos (ej: 10:00:00, 10:03:00)
- **GET**: Se ejecuta en `:10` segundos (ej: 10:00:10, 10:01:10)
- Evita colisiones entre tipos de tareas

### Flujo de PrevenciÃ³n

```
Tarea lista para ejecutar:
â”‚
â”œâ”€ 1. Verificar capacidad Celery
â”‚  â””â”€ Si saturado â†’ Encolar
â”‚
â”œâ”€ 2. Verificar si OLT estÃ¡ ocupada
â”‚  â””â”€ Si ocupada â†’ Encolar en Redis
â”‚
â”œâ”€ 3. Verificar lock anti-duplicados
â”‚  â””â”€ Si existe lock â†’ Skip
â”‚
â”œâ”€ 4. Verificar last_run_at
â”‚  â””â”€ Si < 3 segundos â†’ Skip
â”‚
â””â”€ 5. Ejecutar
   â””â”€ Crear Execution (PENDING)
   â””â”€ Enviar a Celery
   â””â”€ Actualizar next_run_at con desfase
```

---

## ğŸ”„ Flujos Detallados

### Flujo 1: Tarea Lista - OLT Libre

```
1. Coordinator Loop detecta:
   â””â”€ SnmpJobHost.next_run_at <= now
   â””â”€ Ejemplo: 10:00:00 <= 10:00:05

2. Dynamic Scheduler obtiene tareas listas:
   â””â”€ Ordena por prioridad (Discovery primero)
   â””â”€ Ejemplo: [Discovery ONUs (P90), GET Estado (P40)]

3. Verifica si OLT estÃ¡ ocupada:
   â””â”€ is_olt_busy() â†’ False
   â””â”€ No hay Execution RUNNING
   â””â”€ No hay lock de ejecuciÃ³n

4. Verifica capacidad Celery:
   â””â”€ _check_celery_capacity('descubrimiento') â†’ True
   â””â”€ Hay menos de 25 Discovery PENDING

5. Ejecuta tarea:
   â”œâ”€ Lock atÃ³mico (5s): lock:execution:{olt_id}:{job_id}
   â”œâ”€ Verifica last_run_at (no < 3s)
   â”œâ”€ Actualiza next_run_at:
   â”‚  â””â”€ Discovery â†’ now + interval + desfase :00
   â”‚  â””â”€ Ejemplo: 10:00:05 + 180s = 10:03:05 â†’ 10:03:00
   â”œâ”€ Crea Execution (PENDING)
   â”œâ”€ EnvÃ­a a Celery: discovery_main_task.delay(...)
   â””â”€ Log: "â–¶ï¸ Ejecutando: Discovery ONUs en SMP-10 (P90)"

6. Worker Celery ejecuta:
   â””â”€ discovery_main_task recoge tarea
   â””â”€ Ejecuta SNMP walk/GET
   â””â”€ Actualiza Execution (SUCCESS/FAILED)

7. Callback ejecuta:
   â””â”€ on_task_completed() verifica cola
   â””â”€ Si hay tareas â†’ ejecuta siguiente INMEDIATAMENTE
```

### Flujo 2: Tarea Lista - OLT Ocupada

```
1. Coordinator Loop detecta:
   â””â”€ SnmpJobHost.next_run_at <= now
   â””â”€ Ejemplo: GET Estado (10:00:10 <= 10:00:15)

2. Dynamic Scheduler obtiene tareas listas:
   â””â”€ Ordena por prioridad
   â””â”€ Ejemplo: [GET Estado (P40)]

3. Verifica si OLT estÃ¡ ocupada:
   â””â”€ is_olt_busy() â†’ True
   â””â”€ Hay Execution RUNNING (Discovery en curso)

4. Verifica si ya estÃ¡ en cola:
   â””â”€ Redis: olt:queue:{olt_id}
   â””â”€ Si no estÃ¡ â†’ Encolar

5. Encola en Redis:
   â”œâ”€ Redis.lpush(olt:queue:{olt_id}, {
   â”‚  â”œâ”€ job_id: 123,
   â”‚  â”œâ”€ job_name: "GET Estado",
   â”‚  â”œâ”€ job_type: "get",
   â”‚  â””â”€ priority: 40
   â”‚  })
   â””â”€ Log: "ğŸ“‹ GET Estado encolada en SMP-10 (OLT ocupada)"

6. Espera a que termine tarea actual:
   â””â”€ Discovery termina â†’ on_task_completed()
   â””â”€ Callback verifica cola
   â””â”€ Ejecuta siguiente INMEDIATAMENTE
```

### Flujo 3: Callback Ejecuta Siguiente

```
1. Tarea termina en Worker:
   â””â”€ discovery_main_task completa
   â””â”€ Execution.status = SUCCESS

2. Worker llama callback:
   â””â”€ on_task_completed(olt_id, execution_id, ...)

3. Callback verifica cola Redis:
   â””â”€ Redis.lrange(olt:queue:{olt_id}, 0, -1)
   â””â”€ Si hay tareas â†’ procesar

4. Lock temporal:
   â””â”€ lock:processing_queue:{olt_id} (10s)
   â””â”€ Previene procesamiento simultÃ¡neo

5. Obtiene siguiente tarea:
   â””â”€ Redis.rpop(olt:queue:{olt_id})
   â””â”€ Ordena por prioridad (si hay mÃºltiples)

6. Ejecuta siguiente:
   â””â”€ _execute_task_now(task_info, olt)
   â””â”€ Crea Execution (PENDING)
   â””â”€ EnvÃ­a a Celery
   â””â”€ Log: "â–¶ï¸ Ejecutando siguiente: GET Estado en SMP-10 (P40)"

7. Si hay mÃ¡s tareas:
   â””â”€ Repite desde paso 5
   â””â”€ Hasta que cola estÃ© vacÃ­a
```

### Flujo 4: SaturaciÃ³n del Sistema

```
1. Coordinator intenta ejecutar:
   â””â”€ Tarea lista: Discovery ONUs

2. Verifica capacidad Celery:
   â””â”€ _check_celery_capacity('descubrimiento')
   â””â”€ Pending count = 25 (lÃ­mite alcanzado)

3. Sistema saturado:
   â””â”€ Log: "âš ï¸ Sistema saturado: 25 tareas descubrimiento PENDING"
   â””â”€ NO ejecuta
   â””â”€ Espera a que termine alguna tarea

4. PrÃ³ximo loop (5 segundos despuÃ©s):
   â””â”€ Vuelve a verificar capacidad
   â””â”€ Si hay espacio â†’ ejecuta
```

---

## ğŸ”§ IntegraciÃ³n con Celery

### Â¿QuÃ© es Celery?

**Celery** es un sistema de colas de tareas distribuidas que permite ejecutar tareas de forma asÃ­ncrona en workers separados.

### ConfiguraciÃ³n de Celery

```python
# core/settings.py

CELERY_BROKER_URL = 'redis://localhost:6379/0'
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'

CELERY_TASK_ROUTES = {
    'snmp_jobs.tasks.discovery_main_task': {'queue': 'discovery_main'},
    'snmp_jobs.tasks.discovery_retry_task': {'queue': 'discovery_retry'},
    'snmp_get.tasks.get_main_task': {'queue': 'get_main'},
    'snmp_get.tasks.get_retry_task': {'queue': 'get_retry'},
    'execution_coordinator.tasks.coordinator_loop_task': {'queue': 'coordinator'},
}

CELERY_WORKER_CONCURRENCY = 20
```

### Colas de Celery

| Cola | PropÃ³sito | Workers |
|------|-----------|---------|
| `discovery_main` | Tareas de descubrimiento principales | 5-10 |
| `discovery_retry` | Reintentos de descubrimiento | 2-3 |
| `get_main` | Tareas GET principales | 5-10 |
| `get_retry` | Reintentos GET | 2-3 |
| `coordinator` | Loop del coordinador | 1 |

### Flujo con Celery

```
1. Coordinador decide ejecutar tarea:
   â””â”€ _execute_task_now()
   â””â”€ Crea Execution (PENDING)

2. EnvÃ­a a Celery:
   â””â”€ discovery_main_task.delay(snmp_job_id, olt_id, execution_id)
   â””â”€ Celery encola en redis://localhost:6379/0

3. Worker Celery recoge tarea:
   â””â”€ Worker escucha cola 'discovery_main'
   â””â”€ Recoge tarea de Redis
   â””â”€ Ejecuta funciÃ³n discovery_main_task()

4. Worker ejecuta SNMP:
   â””â”€ Conecta a OLT
   â””â”€ Ejecuta SNMP walk/GET
   â””â”€ Procesa resultados
   â””â”€ Guarda en BD

5. Worker actualiza Execution:
   â””â”€ Execution.status = SUCCESS/FAILED
   â””â”€ Execution.finished_at = now()

6. Worker llama callback:
   â””â”€ on_task_completed(olt_id, execution_id, ...)
   â””â”€ Callback ejecuta siguiente en cola
```

### Ventajas de Celery

1. **Escalabilidad**: MÃºltiples workers pueden ejecutar tareas en paralelo
2. **Resiliencia**: Si un worker falla, otra tarea puede tomar su lugar
3. **PriorizaciÃ³n**: Colas separadas permiten priorizar tipos de tareas
4. **Monitoreo**: Celery Flower permite monitorear workers y tareas

---

## ğŸ“Š Resumen de Dependencias

### JerarquÃ­a de Dependencias

```
WorkflowTemplate (Plantilla)
    â”‚
    â”œâ”€ WorkflowTemplateNode (Nodo de plantilla)
    â”‚  â”‚
    â”‚  â””â”€ OID (Dependencia directa)
    â”‚     â”œâ”€ Define marca
    â”‚     â”œâ”€ Define modelo
    â”‚     â””â”€ Define espacio (descubrimiento/get)
    â”‚        â”‚
    â”‚        â””â”€ TaskFunction (segÃºn espacio)
    â”‚           â””â”€ TaskTemplate (funciÃ³n a ejecutar)
    â”‚
    â””â”€ Aplicado a OLTs
       â”‚
       â””â”€ OLTWorkflow (Instancia)
          â”‚
          â””â”€ WorkflowNode (Nodo real)
             â”‚
             â””â”€ SnmpJob (Plantilla de tarea)
                â”‚
                â””â”€ SnmpJobHost (Instancia por OLT)
                   â”‚
                   â””â”€ Execution (EjecuciÃ³n real)
                      â”‚
                      â””â”€ Celery Task
                         â””â”€ Worker ejecuta SNMP
```

### Dependencias Clave

1. **WorkflowTemplateNode â†’ OID**: Directa y obligatoria
2. **OID â†’ TaskTemplate**: Indirecta (segÃºn espacio)
3. **WorkflowNode â†’ SnmpJob**: ConversiÃ³n automÃ¡tica
4. **SnmpJobHost â†’ Execution**: Una ejecuciÃ³n por vez
5. **Execution â†’ Celery Task**: EnvÃ­o asÃ­ncrono

---

## ğŸ“ ConclusiÃ³n

El sistema de workflows de Facho Deluxe v2 es un sistema complejo pero bien estructurado que:

- âœ… **Separa responsabilidades**: Plantillas vs Instancias
- âœ… **Depende de OIDs**: Define operaciones de forma centralizada
- âœ… **Coordina ejecuciones**: Evita colisiones y saturaciÃ³n
- âœ… **Prioriza tareas**: Discovery siempre primero
- âœ… **Escala con Celery**: MÃºltiples workers ejecutan en paralelo
- âœ… **Previene saturaciÃ³n**: LÃ­mites de capacidad y colas por OLT

Este diseÃ±o permite gestionar cientos de OLTs con miles de tareas SNMP de forma eficiente y coordinada.

---

## ğŸ“š Referencias

- `snmp_jobs/models.py`: Modelos de workflows y tareas
- `snmp_jobs/services/workflow_template_service.py`: LÃ³gica de aplicaciÃ³n de plantillas
- `execution_coordinator/coordinator.py`: Coordinador principal
- `execution_coordinator/dynamic_scheduler.py`: Scheduler dinÃ¡mico
- `execution_coordinator/callbacks.py`: Callbacks de ejecuciÃ³n
- `execution_coordinator/COORDINATOR_GUIDE.md`: GuÃ­a detallada del coordinador

