"""
Tareas Celery del Coordinator

- coordinator_loop_task: Loop principal que se ejecuta cada 5 segundos
- check_delivery_task: Verifica que tareas fueron entregadas a Celery (cada 30s)
- cleanup_old_coordinator_logs: Limpieza de logs antiguos
"""

from celery import shared_task
from django.utils import timezone
from datetime import timedelta
import logging

from .coordinator import ExecutionCoordinator
from .logger import coordinator_logger
from .delivery_checker import check_pending_deliveries

logger = logging.getLogger(__name__)


def _auto_fix_offset(olt_id):
    """
    Verifica y corrige autom√°ticamente el desfase de tareas
    
    DESFASE ESPERADO:
    - Discovery: segundo 00
    - GET:       segundo 10
    
    Esta funci√≥n se ejecuta cada vez que el coordinator procesa una OLT,
    garantizando que el desfase siempre est√© correcto sin intervenci√≥n manual.
    """
    from snmp_jobs.models import SnmpJobHost
    
    # Obtener tareas de esta OLT que necesitan correcci√≥n
    job_hosts = SnmpJobHost.objects.filter(
        olt_id=olt_id,
        enabled=True,
        snmp_job__enabled=True,
        next_run_at__isnull=False
    ).select_related('snmp_job')
    
    corrected = 0
    
    for jh in job_hosts:
        current_second = jh.next_run_at.second
        expected_second = 0 if jh.snmp_job.job_type == 'descubrimiento' else 10
        
        # Si el segundo NO es el esperado, corregir
        if current_second != expected_second:
            # Mantener la fecha/hora pero ajustar el segundo
            jh.next_run_at = jh.next_run_at.replace(second=expected_second, microsecond=0)
            jh.save(update_fields=['next_run_at'])
            corrected += 1
    
    if corrected > 0:
        logger.info(f"üîß Auto-correcci√≥n: {corrected} tarea(s) ajustadas en OLT {olt_id}")


@shared_task(queue='coordinator', bind=True)
def coordinator_loop_task(self):
    """
    Loop principal del coordinator
    Se ejecuta cada 5 segundos para todas las OLTs activas
    
    Este es el coraz√≥n del sistema de coordinaci√≥n que:
    1. Lee el estado de cada OLT activa
    2. Detecta cambios (tareas habilitadas/deshabilitadas, etc.)
    3. Reformula planes din√°micamente
    4. Gestiona prioridades y telemetr√≠a
    """
    from hosts.models import OLT
    
    # Obtener solo OLTs habilitadas
    active_olts = OLT.objects.filter(habilitar_olt=True)
    
    # Solo log si no hay OLTs (situaci√≥n anormal)
    if not active_olts.exists():
        return
    
    # ‚úÖ DISTRIBUCI√ìN DE EJECUCIONES: Verificar y distribuir ejecuciones para evitar saturaci√≥n
    # El coordinador verifica cada 2 minutos c√≥mo se ejecutan las OLTs y distribuye
    # las ejecuciones en un rango de hasta 3 minutos (una vez por loop, no por cada OLT)
    # IMPORTANTE: La funci√≥n tiene un lock interno de 2 minutos para evitar redistribuciones constantes
    from .dynamic_scheduler import DynamicScheduler
    DynamicScheduler.distribute_workflow_executions()
    
    # ‚úÖ L√ìGICA AVANZADA: Verificar capacidad de pollers y atrasar ejecuciones si est√°n saturados
    # Si hay ejecuciones que duran m√°s de 1 minuto y los pollers est√°n saturados,
    # atrasa las siguientes ejecuciones en 10 segundos hasta que haya espacio
    DynamicScheduler.check_poller_capacity_and_delay()
    
    changes_detected = False
    
    for olt in active_olts:
        try:
            # VERIFICAR Y CORREGIR DESFASE AUTOM√ÅTICAMENTE
            _auto_fix_offset(olt.id)
            
            coordinator = ExecutionCoordinator(olt.id)
            
            # 1. Leer estado actual
            current_state = coordinator.get_system_state()
            
            if not current_state:
                continue
            
            # 2. Obtener estado anterior
            previous_state = coordinator.get_previous_state()
            
            # 3. Calcular hashes para detecci√≥n r√°pida de cambios
            current_hash = coordinator.calculate_state_hash(current_state)
            previous_hash = coordinator.calculate_state_hash(previous_state) if previous_state else None
            
            # 4. SCHEDULER DIN√ÅMICO: Procesar tareas listas
            # CR√çTICO: Se ejecuta SIEMPRE en cada loop (no solo cuando hay cambios)
            # Esto garantiza:
            # - Auto-reparaci√≥n de JobHosts sin next_run_at (cada 5s)
            # - Ejecuci√≥n de tareas listas aunque no haya cambios de estado
            scheduler = DynamicScheduler(olt.id)
            # Solo 1 nodo a la vez por OLT, pero el sistema puede ejecutar nodos de diferentes OLTs simult√°neamente
            tasks_processed = scheduler.process_ready_tasks(olt)
            
            if tasks_processed > 0:
                coordinator_logger.info(
                    f"üöÄ {tasks_processed} tarea(s) lista(s) procesada(s) en {olt.abreviatura}",
                    olt=olt,
                    event_type='EXECUTION_STARTED',
                    details={'tasks_count': tasks_processed}
                )
            
            # 5. Detectar y manejar cambios de estado si los hay
            has_active_tasks = current_state.get('tasks', [])
            
            if current_hash != previous_hash and has_active_tasks:
                changes_detected = True
                
                # Detectar cambios espec√≠ficos
                changes_info = coordinator.detect_changes(current_state, previous_state)
                
                # Solo loguear si hay cambios SIGNIFICATIVOS (tareas agregadas/removidas)
                if changes_info.get('tasks_added') or changes_info.get('tasks_removed'):
                    coordinator_logger.info(
                        f"üîÑ Cambios detectados en {olt.abreviatura}",
                        olt=olt,
                        event_type='STATE_CHANGE'
                    )
                
                # Manejar los cambios
                coordinator.handle_changes(changes_info)
            
            # 6. Guardar estado actual (siempre, para tener timestamp actualizado)
            coordinator.save_state(current_state)
            
        except Exception as e:
            coordinator_logger.error(
                f"Error en coordinator loop para OLT {olt.id}: {e}",
                olt=olt,
                details={'error': str(e), 'olt_id': olt.id}
            )
            continue


@shared_task(queue='coordinator', bind=True)
def check_quota_violations_task(self):
    """
    Tarea legacy mantenida para compatibilidad con configuraciones antiguas.
    El sistema de cuotas ya no est√° activo, as√≠ que simplemente registramos el llamado.
    """
    coordinator_logger.info(
        "check_quota_violations_task ignorada (sistema de cuotas desactivado)",
        event_type='STATE_UPDATED',
        details={'task': 'check_quota_violations_task'}
    )
    return {
        'status': 'skipped',
        'reason': 'quota system disabled'
    }


@shared_task(queue='cleanup', bind=True)
def cleanup_old_coordinator_logs_task(self, days_old=7):
    """
    Limpia logs del coordinator m√°s antiguos que X d√≠as
    Se ejecuta diariamente
    """
    from .models import CoordinatorLog
    
    cutoff_date = timezone.now() - timedelta(days=days_old)
    
    deleted_count, _ = CoordinatorLog.objects.filter(
        timestamp__lt=cutoff_date
    ).delete()
    
    if deleted_count > 0:
        coordinator_logger.info(
            f"üßπ Limpieza de logs: {deleted_count} registros eliminados (m√°s de {days_old} d√≠as)",
            event_type='STATE_CHANGE'
        )
    
    return {
        'status': 'success',
        'deleted_count': deleted_count,
        'cutoff_date': cutoff_date.isoformat()
    }


@shared_task(bind=True, name='execution_coordinator.tasks.check_delivery_task')
def check_delivery_task(self):
    """
    Verifica que tareas PENDING fueron entregadas a Celery
    
    Ejecuta cada 30 segundos para detectar tareas "perdidas" que:
    - Se crearon en la BD
    - Se enviaron a Celery (.delay())
    - Pero nunca fueron recogidas por un worker
    
    Si una tarea est√° PENDING > 30s y no aparece en Celery:
    - La marca como INTERRUPTED
    - Loguea el problema
    - Las estad√≠sticas se usan para monitoreo
    """
    try:
        stats = check_pending_deliveries()
        
        # Solo loguear si hay p√©rdidas o si se revisaron tareas
        if stats['lost'] > 0:
            coordinator_logger.warning(
                f"‚ö†Ô∏è Verificaci√≥n de entregas: {stats['lost']} de {stats['checked']} tareas perdidas",
                event_type='DELIVERY_CHECK',
                details=stats
            )
        # Si checked > 0 pero lost == 0, todo est√° bien (no loguear)
        
        # Retornar stats para monitoreo pero sin logging autom√°tico de Celery
        # (el loglevel WARNING ya filtra los INFO de Celery)
        return stats
        
    except Exception as e:
        logger.error(f"Error en check_delivery_task: {e}")
        return {
            'status': 'error',
            'error': str(e)
        }

