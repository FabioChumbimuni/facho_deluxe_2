# üìã RESUMEN COMPLETO: Lo que hace el COORDINADOR (Supervisor) a los NODOS

## üéØ FUNCI√ìN PRINCIPAL
El **Coordinador** es el supervisor que gestiona y orquesta todos los nodos de los workflows de las OLTs. Se ejecuta constantemente (cada 5 segundos) y realiza m√∫ltiples funciones para asegurar que los nodos se ejecuten correctamente.

---

## üîÑ FUNCIONES QUE EJECUTA EL COORDINADOR

### 1. **DISTRIBUCI√ìN DE EJECUCIONES** (Cada 2 minutos)
**Funci√≥n:** `distribute_workflow_executions()`

**Qu√© hace:**
- ‚úÖ Verifica constantemente c√≥mo se ejecutan las OLTs
- ‚úÖ Detecta cuando m√∫ltiples OLTs tienen el mismo tiempo de ejecuci√≥n (mismo minuto)
- ‚úÖ Distribuye las ejecuciones en un rango de hasta 3 minutos (-90 a +90 segundos)
- ‚úÖ Evita que todas las OLTs se ejecuten al mismo tiempo (saturaci√≥n del CPU)
- ‚úÖ Respeta el intervalo de cada nodo (cada nodo tiene su propio intervalo, no es fijo)
- ‚úÖ Solo distribuye nodos con intervalos >= 15 minutos

**C√≥mo funciona:**
- Agrupa ejecuciones por minuto objetivo (ej: 16:57:00)
- Si hay m√∫ltiples ejecuciones en el mismo minuto, las distribuye uniformemente
- Aplica desfase sim√©trico: -90, -72, -54, ..., 0, ..., +54, +72, +90 segundos
- Solo actualiza si el cambio es > 30 segundos y el nuevo tiempo est√° en el futuro
- No redistribuye si la ejecuci√≥n est√° a < 60 segundos de ejecutarse

**Lock:** Se ejecuta cada 2 minutos (no cada 5 segundos) usando lock de Redis

---

### 2. **VERIFICACI√ìN DE CAPACIDAD DE POLLERS** (Cada 5 segundos)
**Funci√≥n:** `check_poller_capacity_and_delay()`

**Qu√© hace:**
- ‚úÖ Detecta ejecuciones RUNNING que duran m√°s de 1 minuto
- ‚úÖ Verifica la capacidad de los pollers (workers de Celery):
  - `discovery_main`: 20 workers
  - `get_poller`: 20 workers
  - `get_main`: 20 workers
- ‚úÖ Si los pollers est√°n saturados (>= 80% capacidad), atrasa ejecuciones
- ‚úÖ Aplica tanto a nodos master como a nodos en cadena
- ‚úÖ Atrasa en 10 segundos por iteraci√≥n hasta que haya espacio

**C√≥mo funciona:**
- Cuenta tareas activas en workers de discovery y GET
- Si una ejecuci√≥n dura > 1 minuto Y los pollers est√°n >= 80% saturados:
  - Busca el siguiente nodo a ejecutar (master o cadena)
  - Atrasa `next_run_at` en 10 segundos
  - Aplica aunque sea nodo en cadena (para evitar p√©rdidas)
  - Repite hasta que haya espacio en los pollers

---

### 3. **AUTO-REPARACI√ìN DE NODOS** (Cada 5 segundos)
**Funci√≥n:** `get_ready_tasks()` (dentro de `process_ready_tasks()`)

**Qu√© hace:**
- ‚úÖ Detecta nodos master sin `next_run_at` configurado
- ‚úÖ Los inicializa autom√°ticamente usando `initialize_next_run()`
- ‚úÖ Solo repara nodos master (los nodos en cadena no tienen `next_run_at` por dise√±o)

**C√≥mo funciona:**
- Busca nodos habilitados, master, sin `next_run_at`
- Llama a `initialize_next_run()` para calcular el pr√≥ximo tiempo
- Guarda el `next_run_at` calculado
- Logs: "üîß Auto-reparaci√≥n: X WorkflowNode(s) sin next_run_at"

---

### 4. **VERIFICACI√ìN DE NODOS LISTOS** (Cada 5 segundos)
**Funci√≥n:** `get_ready_tasks()`

**Qu√© hace:**
- ‚úÖ Lee todos los nodos master del workflow de la OLT
- ‚úÖ Filtra nodos con `next_run_at <= now - 30 segundos` (margen de seguridad)
- ‚úÖ Verifica que el nodo pueda ejecutarse (`can_execute_now()`)
- ‚úÖ Verifica que NO haya ejecuci√≥n PENDING o RUNNING para el nodo
- ‚úÖ Ordena por prioridad (descubrimiento=90, GET=40)
- ‚úÖ Solo incluye nodos con OID (directo o desde template_node)

**C√≥mo funciona:**
- Filtra: `enabled=True`, `is_chain_node=False`, `next_run_at <= safe_time`
- Verifica dependencias y que no haya ejecuciones duplicadas
- Determina tipo (descubrimiento/GET) desde el OID
- Retorna lista ordenada por prioridad

---

### 5. **PROCESAMIENTO DE TAREAS LISTAS** (Cada 5 segundos)
**Funci√≥n:** `process_ready_tasks()`

**Qu√© hace:**
- ‚úÖ Procesa nodos listos para ejecutar
- ‚úÖ Verifica si la OLT est√° ocupada (1 ejecuci√≥n a la vez por OLT)
- ‚úÖ Si OLT ocupada: encola todos los nodos (NO SE PIERDEN)
- ‚úÖ Si OLT libre: ejecuta el nodo de mayor prioridad
- ‚úÖ Encola el resto para ejecutar despu√©s
- ‚úÖ Verifica capacidad de Celery antes de ejecutar

**C√≥mo funciona:**
1. Obtiene nodos listos (`get_ready_tasks()`)
2. Verifica si OLT est√° ocupada (`is_olt_busy()`)
3. Si ocupada: encola todos en Redis (cola por OLT)
4. Si libre: ejecuta el primero (mayor prioridad) con `_execute_task_now()`
5. Encola el resto para ejecutar cuando termine el primero

**Logs:** "üìû WORKFLOW ‚Üí COORDINADOR: X nodo(s) listo(s)..."

---

### 6. **VERIFICACI√ìN DE CAPACIDAD DE CELERY** (Antes de ejecutar)
**Funci√≥n:** `_check_celery_capacity()`

**Qu√© hace:**
- ‚úÖ Verifica si hay capacidad en Celery para ejecutar una tarea
- ‚úÖ L√≠mites: 20 ejecuciones PENDING por tipo (descubrimiento o GET)
- ‚úÖ Si est√° saturado, encola la tarea (NO SE PIERDE)

**C√≥mo funciona:**
- Cuenta ejecuciones PENDING del mismo tipo
- Si `pending_count >= 20`: retorna False (saturado)
- Si `pending_count < 20`: retorna True (hay capacidad)

---

### 7. **EJECUCI√ìN DE TAREAS** (Cuando hay capacidad)
**Funci√≥n:** `_execute_task_now()`

**Qu√© hace:**
- ‚úÖ Ejecuta una tarea INMEDIATAMENTE si hay capacidad
- ‚úÖ Verifica que NO haya ejecuci√≥n PENDING o RUNNING para el nodo
- ‚úÖ Usa lock at√≥mico para evitar duplicados
- ‚úÖ Actualiza `next_run_at` ANTES de crear ejecuci√≥n
- ‚úÖ Aplica distribuci√≥n de tiempo (desfase por OLT ID)
- ‚úÖ Crea Execution en BD (PENDING)
- ‚úÖ Env√≠a a Celery (`.delay()`)
- ‚úÖ Actualiza `last_run_at` del WorkflowNode

**C√≥mo funciona:**
1. Obtiene WorkflowNode
2. Verifica OID (directo o desde template_node)
3. Busca/crea SnmpJob y SnmpJobHost (compatibilidad legacy)
4. Verifica capacidad de Celery
5. Verifica que no haya ejecuci√≥n duplicada
6. Lock at√≥mico (5 segundos)
7. Verifica `last_run_at` (no ejecutar si < 3 segundos)
8. Calcula y actualiza `next_run_at` (con distribuci√≥n si es descubrimiento)
9. Crea Execution (PENDING)
10. Env√≠a a Celery
11. Actualiza `last_run_at`

**Distribuci√≥n aplicada:**
- Para descubrimiento con intervalo >= 15 min:
  - Alinea a minutos :12, :27, :42, :57
  - Aplica desfase √∫nico por OLT ID (-90 a +90 segundos)
  - Distribuye para evitar saturaci√≥n

---

### 8. **GESTI√ìN DE COLAS** (Cuando OLT est√° ocupada)
**Funci√≥n:** `enqueue_task()` y `execute_next_in_queue()`

**Qu√© hace:**
- ‚úÖ Encola tareas cuando la OLT est√° ocupada
- ‚úÖ Usa Redis para almacenar cola por OLT
- ‚úÖ Ordena por prioridad (mayor primero)
- ‚úÖ Ejecuta siguiente en cola cuando termina una ejecuci√≥n

**C√≥mo funciona:**
- Cola en Redis: `queue:olt:{olt_id}:pending`
- Almacena: `workflow_node_id`, `node_name`, `job_type`, `priority`
- Cuando termina una ejecuci√≥n, el callback ejecuta `execute_next_in_queue()`
- Toma la tarea de mayor prioridad y la ejecuta

---

### 9. **EJECUCI√ìN DE NODOS EN CADENA** (Cuando master termina)
**Funci√≥n:** `on_task_completed()` en `callbacks.py`

**Qu√© hace:**
- ‚úÖ Cuando un nodo master termina (SUCCESS o FAILED), ejecuta nodos en cadena
- ‚úÖ Verifica que el master haya terminado completamente
- ‚úÖ Para discovery, verifica que tenga `result_summary` procesado
- ‚úÖ Ejecuta el primer nodo de la cadena inmediatamente
- ‚úÖ Cuando un nodo en cadena termina, ejecuta el siguiente en la cadena

**C√≥mo funciona:**
1. Master termina ‚Üí busca nodos en cadena (`get_chain_nodes()`)
2. Verifica que el master termin√≥ completamente (estado, `finished_at`, `result_summary`)
3. Ejecuta primer nodo de cadena si OLT est√° libre y hay capacidad
4. Si no puede ejecutar, encola (NO SE PIERDE)
5. Cuando nodo en cadena termina ‚Üí ejecuta siguiente en cadena
6. Cuando √∫ltimo nodo en cadena termina ‚Üí cadena completada

**Logs:** "üìû WORKFLOW ‚Üí COORDINADOR: Master completado, ejecutando X nodo(s) en cadena..."

---

### 10. **ACTUALIZACI√ìN DE NEXT_RUN_AT** (Despu√©s de ejecutar)
**Funci√≥n:** `_execute_task_now()` (dentro del m√©todo)

**Qu√© hace:**
- ‚úÖ Calcula `next_run_at` desde el momento actual + intervalo del nodo
- ‚úÖ Para descubrimiento con intervalo >= 15 min:
  - Alinea a minutos :12, :27, :42, :57
  - Aplica desfase √∫nico por OLT ID para distribuci√≥n
- ‚úÖ Para nodos en cadena: NO actualiza `next_run_at` (se ejecutan secuencialmente)

**C√≥mo funciona:**
- Si es nodo en cadena: `next_run_at = None`, solo actualiza `last_run_at`
- Si es nodo master: `next_run_at = now + interval_seconds`
- Aplica distribuci√≥n si es descubrimiento >= 15 min
- Guarda en BD antes de crear ejecuci√≥n

---

### 11. **VERIFICACI√ìN DE ENTREGAS A CELERY** (Cada 30 segundos)
**Funci√≥n:** `check_pending_deliveries()` en `delivery_checker.py`

**Qu√© hace:**
- ‚úÖ Verifica que tareas PENDING fueron entregadas a Celery
- ‚úÖ Detecta tareas "perdidas" (enviadas pero no recogidas)
- ‚úÖ Si una tarea est√° PENDING > 300 segundos (5 minutos) y no est√° en Celery:
  - Verifica si el sistema est√° saturado
  - Si NO est√° saturado: marca como INTERRUPTED y reencola
  - Si est√° saturado: espera (no marca como perdida)

**C√≥mo funciona:**
- Busca ejecuciones PENDING > 300 segundos con `celery_task_id`
- Verifica en Celery (active, reserved, scheduled)
- Si no est√° en Celery Y sistema NO saturado: marca INTERRUPTED
- Si es discovery: reencola autom√°ticamente
- Si es GET: bloquea OLT temporalmente

---

### 12. **AUTO-CORRECCI√ìN DE DESFASE** (Cada 5 segundos)
**Funci√≥n:** `_auto_fix_offset()` en `tasks.py`

**Qu√© hace:**
- ‚úÖ Verifica y corrige autom√°ticamente el desfase de tareas legacy (SnmpJobHost)
- ‚úÖ Desfase esperado:
  - Discovery: segundo 00
  - GET: segundo 10

**C√≥mo funciona:**
- Lee todos los SnmpJobHost de la OLT
- Verifica si el segundo de `next_run_at` es el esperado
- Si no: corrige ajustando solo el segundo
- Logs solo si corrige algo

---

### 13. **VERIFICACI√ìN DE ESTADO DE OLT** (Cada 5 segundos)
**Funci√≥n:** `is_olt_busy()`

**Qu√© hace:**
- ‚úÖ Verifica si la OLT est√° ocupada ejecutando un nodo
- ‚úÖ Solo permite 1 ejecuci√≥n a la vez por OLT
- ‚úÖ El sistema puede ejecutar nodos de diferentes OLTs simult√°neamente (hasta 20 OLTs)

**C√≥mo funciona:**
- Cuenta ejecuciones RUNNING o PENDING en la OLT
- Si `running_count >= 1`: OLT ocupada
- Si `running_count == 0`: OLT libre

---

### 14. **LOGS Y MONITOREO** (Constante)
**Funci√≥n:** `coordinator_logger` en todos los m√©todos

**Qu√© hace:**
- ‚úÖ Registra todas las acciones del coordinador
- ‚úÖ Logs estructurados con informaci√≥n de OLT, nodo, tiempos, etc.
- ‚úÖ Eventos: `WORKFLOW_TO_COORDINADOR`, `EXECUTION_DISTRIBUTED`, `EXECUTION_DELAYED`, etc.

**Tipos de logs:**
- `üìû WORKFLOW ‚Üí COORDINADOR`: Cuando el workflow llama al coordinador
- `üîÑ COORDINADOR: Distribuci√≥n`: Cuando distribuye ejecuciones
- `‚è±Ô∏è COORDINADOR: Atrasando`: Cuando atrasa por saturaci√≥n de pollers
- `üìä COORDINADOR: Distribuidas`: Resumen de distribuciones
- `‚úÖ Auto-reparado`: Cuando repara nodos sin `next_run_at`

---

## üìä RESUMEN DE FRECUENCIAS

| Funci√≥n | Frecuencia | Descripci√≥n |
|---------|-----------|-------------|
| `coordinator_loop_task` | Cada 5 segundos | Loop principal |
| `distribute_workflow_executions` | Cada 2 minutos | Distribuci√≥n de ejecuciones |
| `check_poller_capacity_and_delay` | Cada 5 segundos | Verificaci√≥n de pollers |
| `process_ready_tasks` | Cada 5 segundos | Procesamiento de nodos listos |
| `check_pending_deliveries` | Cada 30 segundos | Verificaci√≥n de entregas |
| `_auto_fix_offset` | Cada 5 segundos | Correcci√≥n de desfase |

---

## üéØ PRINCIPIOS FUNDAMENTALES

1. **Cada OLT es independiente**: No se combinan ejecuciones entre OLTs
2. **Solo 1 nodo a la vez por OLT**: Previene colisiones
3. **NO SE PIERDEN TAREAS**: Todas se encolan si no se pueden ejecutar
4. **Respeta intervalos**: Cada nodo mantiene su intervalo configurado
5. **Prioridad estricta**: Discovery (90) antes que GET (40)
6. **Distribuci√≥n inteligente**: Evita saturaci√≥n del CPU
7. **Verificaci√≥n constante**: Pollers, capacidad, entregas, etc.

---

## üîÑ FLUJO COMPLETO DE UN NODO

```
1. Nodo activado ‚Üí initialize_next_run() ‚Üí next_run_at = now + intervalo
2. Coordinador verifica cada 5s ‚Üí get_ready_tasks()
3. Si next_run_at <= now - 30s ‚Üí nodo listo
4. Verifica is_olt_busy() ‚Üí OLT ocupada o libre?
5. Si ocupada ‚Üí enqueue_task() ‚Üí cola Redis
6. Si libre ‚Üí _check_celery_capacity() ‚Üí hay capacidad?
7. Si saturado ‚Üí enqueue_task() ‚Üí cola Redis
8. Si hay capacidad ‚Üí _execute_task_now()
9. Actualiza next_run_at (con distribuci√≥n si aplica)
10. Crea Execution (PENDING)
11. Env√≠a a Celery (.delay())
12. Worker recoge y ejecuta
13. Al terminar ‚Üí on_task_completed()
14. Si es master ‚Üí ejecuta nodos en cadena
15. Si hay cola ‚Üí execute_next_in_queue()
16. Ciclo contin√∫a...
```

---

## ‚ö†Ô∏è PROTECCIONES IMPLEMENTADAS

1. **Lock at√≥mico**: Evita ejecuciones duplicadas
2. **Margen de seguridad**: 30 segundos para evitar ejecuciones inmediatas
3. **Verificaci√≥n de duplicados**: No ejecuta si ya hay PENDING/RUNNING
4. **Verificaci√≥n de last_run_at**: No ejecuta si < 3 segundos desde √∫ltima ejecuci√≥n
5. **Protecci√≥n de ejecuciones inminentes**: No redistribuye si < 60 segundos
6. **Verificaci√≥n de capacidad**: No ejecuta si Celery saturado
7. **Verificaci√≥n de pollers**: Atrasa si pollers saturados
8. **Verificaci√≥n de entregas**: Detecta tareas perdidas

---

## üìù NOTAS IMPORTANTES

- **Nodos en cadena**: NO tienen `next_run_at`, se ejecutan despu√©s del master
- **Nodos master**: Tienen `next_run_at` y se ejecutan seg√∫n intervalo
- **GET independientes**: NO esperan por descubrimientos
- **Items en cadena**: Dependen del master, se ejecutan secuencialmente
- **Distribuci√≥n**: Solo para descubrimiento con intervalo >= 15 min
- **Cada OLT funciona de manera independiente**: No se combinan con otras OLTs

